name: Stan Asset & Template Ingest

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'Ingestion Mode'
        required: true
        type: choice
        options:
          - template        # Full UnityPackage to stan-templates
          - asset-single    # Single file to stan-assets/[type]
          - asset-rip       # UnityPackage to be stripped into stan-assets
      source_url:
        description: 'Public URL or R2 path of the asset/package'
        required: true
        type: string
      temp_path:
        description: 'Temp R2 path to delete after processing (optional)'
        required: false
        type: string
      asset_type:
        description: 'Sub-folder/Category (e.g., sprites, models, racing)'
        required: true
        default: 'misc'
        type: string
      rip_template:
        description: 'If mode is template, also rip assets into stan-assets'
        required: true
        default: true
        type: boolean
      description:
        description: 'Description for Vectorize indexing'
        required: false
        type: string

jobs:
  ingest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: High-Speed Download
        env:
          R2_ACCESS_KEY: ${{ secrets.R2_ACCESS_KEY }}
          R2_SECRET_KEY: ${{ secrets.R2_SECRET_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_PUBLIC_URL: ${{ secrets.R2_PUBLIC_URL }}
        run: |
          mkdir -p raw_data
          SOURCE_URL="${{ github.event.inputs.source_url }}"
          
          # Check if source is R2 path (not a full URL)
          if [[ "$SOURCE_URL" != http* ]]; then
            echo "üì• Downloading from R2 using AWS CLI..."
            pip install awscli
            aws configure set aws_access_key_id $R2_ACCESS_KEY
            aws configure set aws_secret_access_key $R2_SECRET_KEY
            aws configure set default.region auto
            
            # Assume it's a path like "library/sprites/asset.png"
            aws s3 cp s3://stan-assets/$SOURCE_URL raw_data/incoming --endpoint-url $R2_ENDPOINT
          elif [[ "$SOURCE_URL" == *"r2.cloudflarestorage.com"* ]] || [[ "$SOURCE_URL" == *"r2.dev"* ]]; then
            echo "üì• Downloading from R2 dev URL..."
            curl -L -f "$SOURCE_URL" -o raw_data/incoming
          else
            echo "üì• Downloading from public URL..."
            curl -L -f "$SOURCE_URL" -o raw_data/incoming
          fi
          
          if [ ! -f raw_data/incoming ]; then
            echo "‚ùå Download failed!"
            exit 1
          fi
          
          echo "‚úÖ Downloaded from $SOURCE_URL"

      - name: Process Ingestion
        id: process
        run: |
          mkdir -p processed_data
          mkdir -p processed_assets
          MODE="${{ github.event.inputs.mode }}"
          
          # 1. Handle Template Storage
          if [ "$MODE" == "template" ]; then
            echo "üì¶ Mode: Template. Copying to templates/${{ github.event.inputs.asset_type }}"
            mkdir -p "processed_data/templates/${{ github.event.inputs.asset_type }}"
            cp raw_data/incoming "processed_data/templates/${{ github.event.inputs.asset_type }}/base.unitypackage"
          fi

          # 2. Handle Asset Ripping (Mode: asset-rip OR (Mode: template AND rip_template: true))
          RIP_TEMPLATE="${{ github.event.inputs.rip_template }}"
          if [ "$MODE" == "asset-rip" ] || ([ "$MODE" == "template" ] && [ "$RIP_TEMPLATE" == "true" ]); then
            echo "ü™ö Running Asset Ripper..."
            mkdir -p rip_temp
            tar -xzf raw_data/incoming -C rip_temp || true
            
            # Map Unity assets to a clean folder structure in processed_assets
            FIND_PATH="library/ripped/${{ github.event.inputs.asset_type }}"
            find rip_temp -name "pathname" | while read p; do
              DIR=$(dirname "$p")
              FINAL_PATH=$(cat "$p")
              if [ -f "$DIR/asset" ]; then
                mkdir -p "processed_assets/$FIND_PATH/$(dirname "$FINAL_PATH")"
                cp "$DIR/asset" "processed_assets/$FIND_PATH/$FINAL_PATH"
              fi
            done
            echo "‚úÖ Ripping complete"
          fi

          # 3. Handle Single Asset Ingestion
          if [ "$MODE" == "asset-single" ]; then
            echo "üñºÔ∏è Mode: Single Asset."
            mkdir -p "processed_assets/library/${{ github.event.inputs.asset_type }}"
            cp raw_data/incoming "processed_assets/library/${{ github.event.inputs.asset_type }}/asset_$(date +%s)"
          fi

      - name: Sync to Cloudflare R2
        env:
          R2_ACCESS_KEY: ${{ secrets.R2_ACCESS_KEY }}
          R2_SECRET_KEY: ${{ secrets.R2_SECRET_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          pip install awscli
          aws configure set aws_access_key_id $R2_ACCESS_KEY
          aws configure set aws_secret_access_key $R2_SECRET_KEY
          aws configure set default.region auto
          
          # Upload to Templates bucket if needed
          if [ -d "processed_data/templates" ]; then
            echo "üöÄ Syncing to R2 Bucket: stan-templates"
            aws s3 sync processed_data/templates/ s3://stan-templates/ \
              --endpoint-url $R2_ENDPOINT
          fi

          # Upload to Assets bucket if needed
          if [ -d "processed_assets/library" ]; then
            echo "üöÄ Syncing to R2 Bucket: stan-assets"
            aws s3 sync processed_assets/library/ s3://stan-assets/library/ \
              --endpoint-url $R2_ENDPOINT
          fi
          
      - name: Notify Backend for Vectorize
        env:
          STAN_BACKEND_URL: ${{ secrets.STAN_BACKEND_URL }}
          STAN_API_KEY: ${{ secrets.STAN_API_KEY }}
        run: |
          curl -X POST "$STAN_BACKEND_URL/api/admin/index-notify" \
            -H "Authorization: Bearer $STAN_API_KEY" \
            -H "Content-Type: application/json" \
            -d '{
              "mode": "${{ github.event.inputs.mode }}",
              "type": "${{ github.event.inputs.asset_type }}",
              "description": "${{ github.event.inputs.description }}",
              "url": "${{ github.event.inputs.source_url }}",
              "status": "completed"
            }'
      
      - name: Cleanup Temp Files
        if: github.event.inputs.temp_path != ''
        env:
          R2_ACCESS_KEY: ${{ secrets.R2_ACCESS_KEY }}
          R2_SECRET_KEY: ${{ secrets.R2_SECRET_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          echo "üßΩ Cleaning up temp file: ${{ github.event.inputs.temp_path }}"
          pip install awscli
          aws configure set aws_access_key_id $R2_ACCESS_KEY
          aws configure set aws_secret_access_key $R2_SECRET_KEY
          aws configure set default.region auto
          aws s3 rm s3://stan-assets/${{ github.event.inputs.temp_path }} --endpoint-url $R2_ENDPOINT
          echo "‚úÖ Temp file deleted"
